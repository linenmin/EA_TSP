"""
å®¡è®¡æ—¥å¿—æ¨¡å—ï¼šäº‹ä»¶é©±åŠ¨è¯Šæ–­ç³»ç»Ÿ

ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼ï¼š[TAG] event_name | field1=value1 | field2=value2 | ...

Tags:
    [CHK]   - æ ‡å°ºä¸€è‡´æ€§å®¡è®¡ï¼ˆD vs D_lsï¼‰
    [BEST]  - æœ€ä¼˜æ›´æ–°å®¡è®¡
    [RTR]   - RTR æ¥çº³è¡Œä¸ºç”»åƒ
    [POP]   - å¤šæ ·æ€§åˆ†ä½æ•°
    [XOV]   - äº¤å‰è´¡çŒ®å®¡è®¡
    [LS]    - å±€éƒ¨æœç´¢æ”¶ç›Šç”»åƒ
    [LKH]   - LKH å·®å¼‚æ‹“æ‰‘è¶‹åŠ¿
    [GLS]   - GLS çŠ¶æ€å®¡è®¡
    [SCOUT] - Scout è´¡çŒ®å®¡è®¡
    [RST]   - é‡å¯å®¡è®¡
    [TIME]  - æ—¶é—´é¢„ç®—ç”»åƒ
"""

import os
from datetime import datetime
import numpy as np

# å»¶è¿Ÿå¯¼å…¥ tour_length_jitï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
def _get_tour_length_jit():
    from r0927480 import tour_length_jit
    return tour_length_jit

def tour_length_jit(tour, D):
    """åŒ…è£…å‡½æ•°ï¼Œå»¶è¿Ÿå¯¼å…¥"""
    return _get_tour_length_jit()(tour, D)

class AuditLogger:
    """äº‹ä»¶é©±åŠ¨å®¡è®¡æ—¥å¿—å™¨"""
    
    def __init__(self, csv_filename: str):
        """
        åˆå§‹åŒ–æ—¥å¿—å™¨
        
        Args:
            csv_filename: è¾“å…¥çš„ CSV æ–‡ä»¶åï¼ˆå¦‚ 'tour250.csv'ï¼‰
        """
        self.csv_basename = os.path.splitext(os.path.basename(csv_filename))[0]
        self.start_time = datetime.now()
        
        # åˆ›å»º logs ç›®å½•
        self.log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs")
        os.makedirs(self.log_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶å
        timestamp = self.start_time.strftime("%Y%m%d_%H%M%S")
        self.log_filename = os.path.join(self.log_dir, f"audit_{timestamp}_{self.csv_basename}.txt")
        
        # æ‰“å¼€æ—¥å¿—æ–‡ä»¶
        self.file = open(self.log_filename, 'w', encoding='utf-8')
        self._log(f"[INFO] audit_start | csv={self.csv_basename} | time={self.start_time.isoformat()}")
        
        # ç»Ÿè®¡å˜é‡ï¼ˆç”¨äºå‘¨æœŸæ€§ç»Ÿè®¡ï¼‰
        self.rtr_replaced_count = 0
        self.rtr_total_count = 0
        self.rtr_delta_sum = 0.0
        self.rtr_deltas = []  # è®°å½•æ¯æ¬¡æ›¿æ¢çš„ delta
        self.ls_count = 0
        self.ls_gains = []
        
        # P1 æ–°å¢ï¼šè·Ÿè¸ªä¸Šä¸€æ¬¡ best çš„ LKH å¯¹æ¯”ä¿¡æ¯ï¼ˆç”¨äº delta_decompositionï¼‰
        self.prev_shared_with_lkh = 0
        self.prev_missing_count = 0
        self.prev_extra_count = 0
        
        # P3 æ–°å¢ï¼šç®¡é“å®¡è®¡ç»Ÿè®¡
        self.pipe_audit_samples = []  # æ¯ 50 ä»£æ”¶é›†çš„ child å®¡è®¡æ•°æ®
        
        # æ–°å¢ï¼šRTR target è´¨é‡ç»Ÿè®¡
        self.rtr_target_fits = []  # è¢«æŒ‘æˆ˜çš„ target çš„ fitness
        self.rtr_replaced_target_fits = []  # è¢«æ›¿æ¢çš„ target çš„ fitness
        self.rtr_rejected_target_fits = []  # è¢«æ‹’æ”¶æ—¶ target çš„ fitness
        
        # æ–°å¢ï¼šçˆ¶æ¯æ± ç»Ÿè®¡
        self.parent_fits = []  # æœ¬ä»£è¢«é€‰ä½œçˆ¶æ¯çš„ fitness
        
        # æ–°å¢ï¼šHGreX åˆ†å±‚ç»Ÿè®¡
        self.hgrex_parent_edge = 0  # é€‰è‡ªçˆ¶ä»£è¾¹çš„æ¬¡æ•°
        self.hgrex_knn_fallback = 0  # KNN è¡¥æ¼æ¬¡æ•°
        self.hgrex_random_fallback = 0  # éšæœºæ¢é’ˆæ¬¡æ•°
        self.hgrex_fullscan_fallback = 0  # å…¨å›¾æ‰«ææ¬¡æ•°
        self.hgrex_total_steps = 0  # æ€»æ­¥æ•°
        
        # æ–°å¢ï¼šoffspring æµæ°´çº¿ç»Ÿè®¡
        self.pipe_generated = {'hgrex': 0, 'ox': 0, 'mutate': 0}
        self.pipe_feasible = 0  # é€šè¿‡å¯è¡Œæ€§æ£€æŸ¥
        self.pipe_tamed = 0  # è¿›å…¥ boot camp
        self.pipe_submitted = 0  # æäº¤ RTR
        self.pipe_accepted = 0  # RTR æ¥æ”¶
        
        # æ—¶é—´ç»Ÿè®¡
        self.time_xov = 0.0
        self.time_ls = 0.0
        self.time_eval = 0.0
        self.time_scout = 0.0
        self.time_last_report = self.start_time
        
        print(f"ğŸ“ å®¡è®¡æ—¥å¿—: {self.log_filename}")
    
    def _log(self, msg: str):
        """å†…éƒ¨å†™æ—¥å¿—"""
        print(msg)
        self.file.write(msg + "\n")
        self.file.flush()
    
    def close(self):
        """å…³é—­æ—¥å¿—æ–‡ä»¶"""
        elapsed = (datetime.now() - self.start_time).total_seconds()
        self._log(f"[INFO] audit_end | elapsed={elapsed:.1f}s")
        self.file.close()
    
    # =========================================================================
    # P1: æ ‡å°ºä¸€è‡´æ€§å®¡è®¡ [CHK]
    # =========================================================================
    
    def chk_objective_audit(self, gen: int, gls_active: bool, 
                            tour, D, D_ls, fitness_array):
        """
        æ ‡å°ºä¸€è‡´æ€§å®¡è®¡ï¼šæ£€æŸ¥ D ä¸ D_ls æ˜¯å¦æ··ç”¨
        
        Args:
            tour: ç”¨äº spot-check çš„ tour
            D: çœŸå®è·ç¦»çŸ©é˜µ
            D_ls: GLS æƒ©ç½šçŸ©é˜µï¼ˆå¯èƒ½ == Dï¼‰
            fitness_array: ç§ç¾¤ fitness æ•°ç»„
        """
        from r0927480 import tour_length_jit
        
        len_D = tour_length_jit(tour, D)
        len_Dls = tour_length_jit(tour, D_ls) if D_ls is not D else len_D
        
        # Spot checkï¼šå–å‰3ä¸ªä¸ªä½“æ£€æŸ¥
        fit_min = fitness_array.min()
        
        # åˆ¤æ–­æ˜¯å¦ä¸€è‡´
        is_consistent = True
        if gls_active and D_ls is not D:
            # å¦‚æœ fitness æœ€å°å€¼ â‰ˆ len_Dls è€Œä¸æ˜¯ len_Dï¼Œè¯´æ˜ç›®æ ‡è¢«æ±¡æŸ“
            # è¿™é‡Œç®€åŒ–æ£€æŸ¥
            pass
        
        self._log(f"[CHK] objective_audit | gen={gen} | gls={gls_active} | "
                  f"tour_D={len_D:.2f} | tour_Dls={len_Dls:.2f} | fit_min={fit_min:.2f}")
    
    # =========================================================================
    # P2: æœ€ä¼˜æ›´æ–°å®¡è®¡ [BEST]
    # =========================================================================
    
    def best_update_event(self, gen: int, source: str, 
                          old_len: float, new_len: float, tour,
                          lkh_tour=None, D=None):
        """
        æœ€ä¼˜æ›´æ–°äº‹ä»¶å®¡è®¡ + delta_decomposition
        
        è¾“å‡ºæ”¹è¿›æ˜¯å¦çœŸæ­£"å¾€ LKH é è¿‘"
        """
        delta = old_len - new_len
        tour_hash = self._tour_hash(tour)
        
        # LKH å¯¹æ¯”
        shared_count = 0
        missing_count = len(tour)
        extra_count = len(tour)
        sim_lkh = 0.0
        bond = len(tour)
        
        if lkh_tour is not None:
            from diagnose_gap import edge_similarity, bond_distance, get_edges_set
            shared_count, sim_lkh = edge_similarity(tour, lkh_tour)
            bond = bond_distance(tour, lkh_tour)
            
            # è®¡ç®— missing å’Œ extra
            _, my_edges = get_edges_set(tour)
            _, lkh_edges = get_edges_set(lkh_tour)
            missing_count = len(lkh_edges - my_edges)
            extra_count = len(my_edges - lkh_edges)
        
        # è®¡ç®—ä¸ä¸Šä¸€æ¬¡ best çš„å·®å€¼ï¼ˆdelta_decompositionï¼‰
        d_shared = shared_count - self.prev_shared_with_lkh
        d_missing = missing_count - self.prev_missing_count
        d_extra = extra_count - self.prev_extra_count
        
        # æ›´æ–°è·Ÿè¸ªå˜é‡
        self.prev_shared_with_lkh = shared_count
        self.prev_missing_count = missing_count
        self.prev_extra_count = extra_count
        
        self._log(f"[BEST] update | gen={gen} | src={source} | "
                  f"old={old_len:.2f} | new={new_len:.2f} | delta={delta:.2f} | "
                  f"sim_lkh={sim_lkh:.1%} | bond={bond} | hash={tour_hash}")
        
        # P1 æ ¸å¿ƒï¼šdelta_decomposition
        self._log(f"[BEST] delta_decomposition | gen={gen} | "
                  f"Î”shared={d_shared:+d} | Î”missing={d_missing:+d} | Î”extra={d_extra:+d} | "
                  f"shared={shared_count} | missing={missing_count} | extra={extra_count}")
        
        # é¡ºä¾¿è§¦å‘ P6 æ‹“æ‰‘åˆ†æ
        if lkh_tour is not None and D is not None:
            self.lkh_missing_topology(gen, tour, lkh_tour, D)
    
    def _tour_hash(self, tour) -> str:
        """ç”Ÿæˆ tour çš„ç®€çŸ­ hashï¼ˆç”¨äºè¿½è¸ªï¼‰"""
        if len(tour) >= 20:
            key = tuple(tour[:10]) + tuple(tour[-10:])
        else:
            key = tuple(tour)
        return f"{hash(key) & 0xFFFFFFFF:08x}"
    
    # =========================================================================
    # P3: RTR æ¥çº³è¡Œä¸ºç”»åƒ [RTR]
    # =========================================================================
    
    def rtr_record(self, replaced: bool, delta: float, child_len: float = None, target_len: float = None, target_idx: int = None):
        """è®°å½•å•æ¬¡ RTR ç»“æœï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒé‡‡æ ·å®¡è®¡ï¼‰"""
        self.rtr_total_count += 1
        if replaced:
            self.rtr_replaced_count += 1
            self.rtr_delta_sum += delta
            self.rtr_deltas.append(delta)
        
        # RTR-SAMPLEï¼šè®°å½•å•æ¬¡å†³ç­–è¯¦æƒ…
        if child_len is not None and target_len is not None:
            if not hasattr(self, 'rtr_samples'):
                self.rtr_samples = []
            self.rtr_samples.append({
                'child_len': child_len,
                'target_len': target_len,
                'target_idx': target_idx,
                'replaced': replaced,
                'should_replace': child_len < target_len  # ç†è®ºä¸Šåº”è¯¥æ›¿æ¢ï¼Ÿ
            })
    
    def rtr_acceptance_profile(self, gen: int, lam: int):
        """
        è¾“å‡ºå¢å¼ºç‰ˆ RTR é—¨æ§æŠ¥å‘Š + RTR-SAMPLE
        """
        if self.rtr_total_count == 0:
            return
        
        rate = self.rtr_replaced_count / self.rtr_total_count
        avg_delta = self.rtr_delta_sum / max(1, self.rtr_replaced_count)
        
        # è®¡ç®— delta åˆ†ä½æ•°ï¼ˆè¿‡æ»¤ inf/nanï¼‰
        delta_p10, delta_p50, delta_p90 = 0.0, 0.0, 0.0
        if self.rtr_deltas:
            valid_deltas = [d for d in self.rtr_deltas if np.isfinite(d)]
            if valid_deltas:
                deltas = np.array(valid_deltas)
                delta_p10 = np.percentile(deltas, 10)
                delta_p50 = np.percentile(deltas, 50)
                delta_p90 = np.percentile(deltas, 90)
        
        self._log(f"[RTR] gate_report | gen={gen} | children={self.rtr_total_count} | "
                  f"replaced={self.rtr_replaced_count} | rate={rate:.1%} | "
                  f"delta_P10={delta_p10:.2f} | delta_P50={delta_p50:.2f} | delta_P90={delta_p90:.2f}")
        
        # RTR-SAMPLEï¼šè¾“å‡ºé‡‡æ ·è¯¦æƒ…ï¼ˆæœ€å¤š 3 ä¸ªï¼‰
        if hasattr(self, 'rtr_samples') and self.rtr_samples:
            samples = self.rtr_samples[-3:]  # å–æœ€å 3 ä¸ª
            for i, s in enumerate(samples):
                mismatch = "âš ï¸MISMATCH" if s['replaced'] != s['should_replace'] else ""
                self._log(f"[RTR-SAMPLE] #{i+1} | child={s['child_len']:.2f} | target={s['target_len']:.2f} | "
                          f"child<target={s['should_replace']} | replaced={s['replaced']} {mismatch}")
        
        # é‡ç½®è®¡æ•°å™¨
        self.rtr_total_count = 0
        self.rtr_replaced_count = 0
        self.rtr_delta_sum = 0.0
        self.rtr_deltas = []
        self.rtr_samples = []
    
    # =========================================================================
    # P4: å¤šæ ·æ€§åˆ†ä½æ•° [POP]
    # =========================================================================
    
    def pop_diversity_quantiles(self, gen: int, population, best_tour):
        """
        ç§ç¾¤å¤šæ ·æ€§åˆ†ä½æ•°
        
        è®¡ç®—æ‰€æœ‰ä¸ªä½“ä¸ best_tour çš„ bond distance çš„ P10/P50/P90
        """
        from diagnose_gap import bond_distance
        
        n = len(best_tour)
        lam = len(population)
        
        # é‡‡æ ·è®¡ç®— bond distanceï¼ˆå…¨ç®—å¤ªæ…¢ï¼Œé‡‡æ · min(lam, 30) ä¸ªï¼‰
        sample_size = min(lam, 30)
        indices = np.random.choice(lam, sample_size, replace=False)
        
        bonds = []
        for idx in indices:
            bd = bond_distance(population[idx], best_tour)
            bonds.append(bd)
        
        bonds = np.array(bonds)
        p10 = int(np.percentile(bonds, 10))
        p50 = int(np.percentile(bonds, 50))
        p90 = int(np.percentile(bonds, 90))
        
        # ç»Ÿè®¡ distinct
        seen = set()
        for tour in population:
            key = tuple(tour[:10]) + tuple(tour[-10:]) if len(tour) >= 20 else tuple(tour)
            seen.add(key)
        distinct = len(seen)
        
        self._log(f"[POP] diversity | gen={gen} | bond_P10={p10} | bond_P50={p50} | "
                  f"bond_P90={p90} | distinct={distinct}/{lam}")
    
    def pop_quality_profile(self, gen: int, fitness_array, best_fitness: float):
        """
        ç§ç¾¤è´¨é‡ç”»åƒï¼šæ£€æŸ¥ median æ˜¯å¦è¢«åƒåœ¾è§£æ‹–å®
        """
        # è¿‡æ»¤æœ‰æ•ˆå€¼
        valid_fitness = [f for f in fitness_array if np.isfinite(f)]
        invalid_count = len(fitness_array) - len(valid_fitness)
        
        if not valid_fitness:
            self._log(f"[POP] quality_profile | gen={gen} | ALL_INVALID")
            return
        
        fits = np.array(valid_fitness)
        fit_min = fits.min()
        fit_median = np.median(fits)
        fit_max = fits.max()
        best_gap_to_median = fit_median - best_fitness
        
        self._log(f"[POP] quality_profile | gen={gen} | "
                  f"min={fit_min:.2f} | median={fit_median:.2f} | max={fit_max:.2f} | "
                  f"invalid={invalid_count} | best_gap_to_median={best_gap_to_median:.2f}")
    
    # =========================================================================
    # P5: LS æ”¶ç›Šç”»åƒ [LS]
    # =========================================================================
    
    def ls_record(self, gain: float, before_len: float = None, after_len: float = None, 
                  passes: int = None, improvements: int = None):
        """è®°å½•å•æ¬¡ LS æ”¶ç›Šï¼ˆå¢å¼ºç‰ˆï¼šæ£€æµ‹éæ³•å€¼ + VND æ­¥æ•°ï¼‰"""
        self.ls_count += 1
        
        # æ£€æµ‹éæ³•å€¼
        if not np.isfinite(gain):
            self.ls_invalid_count = getattr(self, 'ls_invalid_count', 0) + 1
        else:
            self.ls_gains.append(gain)
        
        # å­˜å‚¨é‡‡æ ·æ•°æ®ï¼ˆç”¨äº LS-SAMPLE + LS-STEPï¼‰
        if before_len is not None and after_len is not None:
            if not hasattr(self, 'ls_samples'):
                self.ls_samples = []
            self.ls_samples.append({
                'before': before_len,
                'after': after_len,
                'gain': gain,
                'before_finite': np.isfinite(before_len),
                'after_finite': np.isfinite(after_len),
                'passes': passes if passes is not None else 0,
                'improvements': improvements if improvements is not None else 0
            })
    
    def ls_gain_profile(self, gen: int):
        """è¾“å‡º LS æ”¶ç›Šç”»åƒï¼ˆä¿®å¤ç‰ˆï¼šè¿‡æ»¤ inf + LS-STEPï¼‰"""
        if self.ls_count == 0:
            return
        
        # è¿‡æ»¤é finite å€¼
        valid_gains = [g for g in self.ls_gains if np.isfinite(g)]
        invalid_count = getattr(self, 'ls_invalid_count', 0)
        
        if valid_gains:
            gains = np.array(valid_gains)
            avg_gain = gains.mean()
            p90_gain = np.percentile(gains, 90)
        else:
            avg_gain = 0.0
            p90_gain = 0.0
        
        self._log(f"[LS] gain_profile | gen={gen} | count={self.ls_count} | "
                  f"valid={len(valid_gains)} | invalid={invalid_count} | "
                  f"avg={avg_gain:.2f} | p90={p90_gain:.2f}")
        
        # LS-STEPï¼šè¾“å‡º VND æ­¥æ•°ç»Ÿè®¡ï¼ˆæœ€å¤š 3 ä¸ªï¼‰
        if hasattr(self, 'ls_samples') and self.ls_samples:
            samples = self.ls_samples[-3:]  # å–æœ€å 3 ä¸ª
            for i, s in enumerate(samples):
                passes = s.get('passes', 0)
                imps = s.get('improvements', 0)
                self._log(f"[LS-STEP] #{i+1} | before={s['before']:.2f} | after={s['after']:.2f} | "
                          f"delta={s['gain']:+.2f} | passes={passes} | improvements={imps}")
        
        # é‡ç½®
        self.ls_count = 0
        self.ls_gains = []
        self.ls_invalid_count = 0
        self.ls_samples = []
    
    # =========================================================================
    # P6: LKH å·®å¼‚æ‹“æ‰‘è¶‹åŠ¿ [LKH]
    # =========================================================================
    
    def lkh_missing_topology(self, gen: int, my_tour, lkh_tour, D):
        """
        åˆ†æä¸ LKH çš„å·®å¼‚æ‹“æ‰‘
        """
        from diagnose_gap import get_edges_set
        
        n = len(my_tour)
        _, my_edges = get_edges_set(my_tour)
        _, lkh_edges = get_edges_set(lkh_tour)
        
        missing = lkh_edges - my_edges
        extra = my_edges - lkh_edges
        missing_count = len(missing)
        extra_count = len(extra)
        
        # åˆ†æ missing çš„æ‹“æ‰‘ç»“æ„
        chains, cycles, complex_knots = self._analyze_topology(list(missing))
        
        self._log(f"[LKH] topology | gen={gen} | missing={missing_count} | "
                  f"chains={chains} | cycles={cycles} | complex={complex_knots} | extra={extra_count}")
    
    def _analyze_topology(self, missing_edges):
        """åˆ†æç¼ºå¤±è¾¹çš„æ‹“æ‰‘ç»“æ„"""
        if not missing_edges:
            return 0, 0, 0
        
        # æ„å»ºé‚»æ¥è¡¨
        adj = {}
        nodes = set()
        for edge in missing_edges:
            edge_list = list(edge)
            if len(edge_list) < 2:
                continue
            u, v = edge_list[0], edge_list[1]
            if u not in adj: adj[u] = []
            if v not in adj: adj[v] = []
            adj[u].append(v)
            adj[v].append(u)
            nodes.add(u)
            nodes.add(v)
        
        # æ‰¾è¿é€šåˆ†é‡
        visited = set()
        chains, cycles, complex_knots = 0, 0, 0
        
        for node in nodes:
            if node in visited:
                continue
            
            # BFS
            component_nodes = []
            stack = [node]
            visited.add(node)
            while stack:
                curr = stack.pop()
                component_nodes.append(curr)
                for neighbor in adj.get(curr, []):
                    if neighbor not in visited:
                        visited.add(neighbor)
                        stack.append(neighbor)
            
            # è®¡ç®—è¾¹æ•°
            comp_edges = sum(len(adj.get(u, [])) for u in component_nodes) // 2
            size = len(component_nodes)
            
            if size == comp_edges:
                cycles += 1
            elif size == comp_edges + 1:
                chains += 1
            else:
                complex_knots += 1
        
        return chains, cycles, complex_knots
    
    # =========================================================================
    # P8: æ—¶é—´é¢„ç®—ç”»åƒ [TIME]
    # =========================================================================
    
    def time_stage_budget(self, gen: int):
        """è¾“å‡ºæ—¶é—´é¢„ç®—ç”»åƒ"""
        total = self.time_xov + self.time_ls + self.time_eval + self.time_scout
        if total < 0.001:
            return
        
        self._log(f"[TIME] budget | gen={gen} | "
                  f"xov={self.time_xov/total:.1%} | ls={self.time_ls/total:.1%} | "
                  f"eval={self.time_eval/total:.1%} | scout={self.time_scout/total:.1%}")
        
        # é‡ç½®
        self.time_xov = 0.0
        self.time_ls = 0.0
        self.time_eval = 0.0
        self.time_scout = 0.0
    
    # =========================================================================
    # å…¶ä»–äº‹ä»¶
    # =========================================================================
    
    def gls_state_change(self, gen: int, activated: bool, stagnation: int):
        """GLS çŠ¶æ€å˜åŒ–"""
        state = "activated" if activated else "deactivated"
        self._log(f"[GLS] {state} | gen={gen} | stagnation={stagnation}")
    
    def scout_event(self, gen: int, event_type: str, scout_fit: float, 
                    best_fit: float, accepted: bool):
        """Scout äº‹ä»¶"""
        self._log(f"[SCOUT] {event_type} | gen={gen} | scout_fit={scout_fit:.2f} | "
                  f"best_fit={best_fit:.2f} | accepted={accepted}")
    
    def restart_event(self, gen: int, old_best: float, reason: str):
        """é‡å¯äº‹ä»¶"""
        self._log(f"[RST] restart | gen={gen} | old_best={old_best:.2f} | reason={reason}")
    
    # =========================================================================
    # P3 æ–°å¢: ç®¡é“å®¡è®¡ [PIPE]
    # =========================================================================
    
    def pipe_child_audit(self, gen: int, 
                         shared_p1: int, shared_p2: int, 
                         shared_lkh_before: int, shared_lkh_after: int,
                         delta_repair: float, delta_ls: float,
                         accepted: bool):
        """
        P3: å•ä¸ª child çš„ç®¡é“å®¡è®¡
        
        è¿½è¸ªäº¤å‰/repair/LS å„é˜¶æ®µå¯¹è¾¹ç»“æ„çš„å½±å“
        """
        self._log(f"[PIPE] child_audit | gen={gen} | "
                  f"shared_p1={shared_p1} | shared_p2={shared_p2} | "
                  f"lkh_before={shared_lkh_before} | lkh_after={shared_lkh_after} | "
                  f"Î”repair={delta_repair:+.2f} | Î”ls={delta_ls:+.2f} | accepted={accepted}")
    
    def pipe_sample_summary(self, gen: int, samples: list):
        """
        P3: å¤šä¸ª child çš„ç®¡é“å®¡è®¡æ±‡æ€»
        
        samples: list of dict {shared_p1, shared_p2, lkh_before, lkh_after, delta_repair, delta_ls, accepted}
        """
        if not samples:
            return
        
        n = len(samples)
        avg_shared_p1 = sum(s['shared_p1'] for s in samples) / n
        avg_shared_p2 = sum(s['shared_p2'] for s in samples) / n
        avg_lkh_before = sum(s['shared_lkh_before'] for s in samples) / n
        avg_lkh_after = sum(s['shared_lkh_after'] for s in samples) / n
        avg_delta_repair = sum(s['delta_repair'] for s in samples) / n
        avg_delta_ls = sum(s['delta_ls'] for s in samples) / n
        accepted_count = sum(1 for s in samples if s['accepted'])
        
        # å…³é”®æŒ‡æ ‡ï¼šLS åä¸ LKH çš„å…±äº«è¾¹æ˜¯å¢åŠ è¿˜æ˜¯å‡å°‘
        lkh_change = avg_lkh_after - avg_lkh_before
        
        self._log(f"[PIPE] summary | gen={gen} | samples={n} | "
                  f"avg_shared_p1={avg_shared_p1:.1f} | avg_shared_p2={avg_shared_p2:.1f} | "
                  f"lkh_before={avg_lkh_before:.1f} | lkh_after={avg_lkh_after:.1f} | "
                  f"lkh_change={lkh_change:+.1f} | "
                  f"Î”repair={avg_delta_repair:+.2f} | Î”ls={avg_delta_ls:+.2f} | accepted={accepted_count}/{n}")
    
    # =========================================================================
    # P4 æ–°å¢: å€™é€‰è¾¹åˆ©ç”¨ç‡ [CAND]
    # =========================================================================
    
    def cand_usage_report(self, gen: int, best_tour, lkh_tour, knn_idx, D):
        """
        P4: å€™é€‰è¾¹åˆ©ç”¨ç‡æŠ¥å‘Š
        
        æ£€æŸ¥ best_tour å’Œ lkh_tour çš„è¾¹æœ‰å¤šå°‘åœ¨å€™é€‰é›†ä¸­
        ä»¥åŠ missing edges æœ‰å¤šå°‘å…¶å®åœ¨å€™é€‰é›†ä¸­ä½†æ²¡è¢«ç”¨ä¸Š
        """
        from diagnose_gap import get_edges_set
        
        n = len(best_tour)
        K = knn_idx.shape[1] if knn_idx is not None else 0
        
        # æ„å»ºå€™é€‰é›†å¿«é€ŸæŸ¥æ‰¾ç»“æ„
        candidate_sets = [set(knn_idx[i]) - {-1} for i in range(n)] if knn_idx is not None else [set() for _ in range(n)]
        
        # best_tour çš„è¾¹ä¸­æœ‰å¤šå°‘åœ¨å€™é€‰é›†å†…
        _, best_edges = get_edges_set(best_tour)
        best_in_cand = 0
        for edge in best_edges:
            edge_list = list(edge)
            if len(edge_list) >= 2:
                u, v = edge_list[0], edge_list[1]
                if v in candidate_sets[u] or u in candidate_sets[v]:
                    best_in_cand += 1
        best_cand_ratio = best_in_cand / len(best_edges) if best_edges else 0
        
        # LKH tour çš„è¾¹ä¸­æœ‰å¤šå°‘åœ¨å€™é€‰é›†å†…
        lkh_in_cand = 0
        if lkh_tour is not None:
            _, lkh_edges = get_edges_set(lkh_tour)
            for edge in lkh_edges:
                edge_list = list(edge)
                if len(edge_list) >= 2:
                    u, v = edge_list[0], edge_list[1]
                    if v in candidate_sets[u] or u in candidate_sets[v]:
                        lkh_in_cand += 1
            lkh_cand_ratio = lkh_in_cand / len(lkh_edges) if lkh_edges else 0
            
            # missing edges ä¸­æœ‰å¤šå°‘åœ¨å€™é€‰é›†å†…
            missing = lkh_edges - best_edges
            missing_in_cand = 0
            for edge in missing:
                edge_list = list(edge)
                if len(edge_list) >= 2:
                    u, v = edge_list[0], edge_list[1]
                    if v in candidate_sets[u] or u in candidate_sets[v]:
                        missing_in_cand += 1
            missing_cand_ratio = missing_in_cand / len(missing) if missing else 1.0
        else:
            lkh_cand_ratio = 0
            missing_in_cand = 0
            missing_cand_ratio = 0
        
        self._log(f"[CAND] usage_report | gen={gen} | "
                  f"best_in_cand={best_cand_ratio:.1%} ({best_in_cand}/{n}) | "
                  f"lkh_in_cand={lkh_cand_ratio:.1%} | "
                  f"missing_in_cand={missing_cand_ratio:.1%} ({missing_in_cand}/{len(missing) if lkh_tour is not None else 0})")
    
    # =========================================================================
    # OX/Repair è¯Šæ–­
    # =========================================================================
    
    def ox_repair_audit(self, gen: int, c_pop, population, fitness, D, best_tour):
        """
        æŠ½æ ·å®¡è®¡ï¼šrepair å child æ˜¯å¦å˜æˆ parent å¤åˆ¶å“ï¼Ÿé•¿åº¦æ˜¯å¦çˆ†ç‚¸ï¼Ÿ
        
        æŠ½æ · 5 ä¸ª child æ£€æŸ¥ï¼š
        1. post_repair_identity: æ˜¯å¦ä¸çˆ¶ä»£/best ç›¸åŒ
        2. repair_damage_report: é•¿åº¦å˜åŒ–
        """
        from diagnose_gap import bond_distance
        
        lam = c_pop.shape[0]
        sample_indices = np.random.choice(lam, min(5, lam), replace=False)
        
        same_as_parent = 0
        same_as_best = 0
        len_exploded = 0  # é•¿åº¦ > best * 3
        
        best_len = tour_length_jit(best_tour, D)
        
        for idx in sample_indices:
            child = c_pop[idx]
            child_len = tour_length_jit(child, D)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ best ç›¸åŒ
            if bond_distance(child, best_tour) == 0:
                same_as_best += 1
            
            # æ£€æŸ¥æ˜¯å¦é•¿åº¦çˆ†ç‚¸
            if child_len > best_len * 3:
                len_exploded += 1
        
        n_samples = len(sample_indices)
        self._log(f"[OX] repair_audit | gen={gen} | samples={n_samples} | "
                  f"same_as_best={same_as_best}/{n_samples} | len_exploded={len_exploded}/{n_samples}")
    
    def ls_overwrite_audit(self, gen: int, tour_hash_before: str, tour_hash_after_ls: str, 
                           tour_hash_after_writeback: str):
        """
        LS è¦†ç›–å®¡è®¡ï¼šæ£€æµ‹ LS çš„æ”¹åŠ¨æ˜¯å¦è¢«åç»­å›æ»š/åŒæ­¥è¦†ç›–
        
        å¦‚æœ (after_ls != before) ä½† (after_writeback == before)ï¼Œè¯´æ˜ LS è¢«è¦†ç›–
        """
        ls_changed = (tour_hash_after_ls != tour_hash_before)
        overwritten = (tour_hash_after_writeback == tour_hash_before) and ls_changed
        
        status = "âš ï¸OVERWRITTEN" if overwritten else ("IMPROVED" if ls_changed else "NO_CHANGE")
        self._log(f"[LS] overwrite_audit | gen={gen} | before={tour_hash_before} | "
                  f"after_ls={tour_hash_after_ls} | writeback={tour_hash_after_writeback} | {status}")

    # =========================================================================
    # å†³å®šæ€§è¯Šæ–­ (4 ç±»æ–°æ—¥å¿—)
    # =========================================================================
    
    def rtr_target_record(self, target_fit: float, replaced: bool):
        """è®°å½• RTR è¢«æŒ‘æˆ˜ target çš„ä¿¡æ¯"""
        self.rtr_target_fits.append(target_fit)
        if replaced:
            self.rtr_replaced_target_fits.append(target_fit)
        else:
            self.rtr_rejected_target_fits.append(target_fit)
    
    def rtr_target_quality_report(self, gen: int, best_fit: float):
        """
        [RTR] target_quality_report
        ç»Ÿè®¡è¢«æŒ‘æˆ˜çš„ target è´¨é‡åˆ†å¸ƒ
        """
        if not self.rtr_target_fits:
            return
        
        fits = np.array(self.rtr_target_fits)
        p10 = np.percentile(fits, 10)
        p50 = np.percentile(fits, 50)
        p90 = np.percentile(fits, 90)
        
        # è¢«æ›¿æ¢çš„ target
        replaced_med = np.median(self.rtr_replaced_target_fits) if self.rtr_replaced_target_fits else 0
        
        # è¢«æ‹’æ”¶æ—¶ target æ˜¯å¦åœ¨ top åŒºï¼ˆ< best * 1.2ï¼‰
        top_rejected = sum(1 for f in self.rtr_rejected_target_fits if f < best_fit * 1.2)
        total_rejected = len(self.rtr_rejected_target_fits)
        
        self._log(f"[RTR] target_quality | gen={gen} | n={len(fits)} | "
                  f"P10={p10:.0f} | P50={p50:.0f} | P90={p90:.0f} | "
                  f"replaced_med={replaced_med:.0f} | top_rejected={top_rejected}/{total_rejected}")
        
        # é‡ç½®
        self.rtr_target_fits = []
        self.rtr_replaced_target_fits = []
        self.rtr_rejected_target_fits = []
    
    def mate_parent_record(self, p1_fit: float, p2_fit: float):
        """è®°å½•çˆ¶æ¯ fitness"""
        self.parent_fits.append(p1_fit)
        self.parent_fits.append(p2_fit)
    
    def mate_parent_pool_report(self, gen: int, best_fit: float, pop_median: float):
        """
        [MATE] parent_pool_report
        ç»Ÿè®¡è¢«é€‰ä½œçˆ¶æ¯çš„ä¸ªä½“è´¨é‡
        """
        if not self.parent_fits:
            return
        
        fits = np.array(self.parent_fits)
        p10 = np.percentile(fits, 10)
        p50 = np.percentile(fits, 50)
        p90 = np.percentile(fits, 90)
        
        # çˆ¶æ¯æ¥è‡ª top 50% çš„æ¯”ä¾‹
        top_half_threshold = pop_median
        top_half = sum(1 for f in fits if f < top_half_threshold)
        top_ratio = top_half / len(fits)
        
        # elite+garbage é…å¯¹æ¯”ä¾‹ï¼ˆfitness æ¯”ç‡ > 2xï¼‰
        # éœ€è¦æˆå¯¹çœ‹
        mismatch_count = 0
        for i in range(0, len(self.parent_fits) - 1, 2):
            f1, f2 = self.parent_fits[i], self.parent_fits[i+1]
            ratio = max(f1, f2) / min(f1, f2) if min(f1, f2) > 0 else 1
            if ratio > 2.0:
                mismatch_count += 1
        total_pairs = len(self.parent_fits) // 2
        
        self._log(f"[MATE] parent_pool | gen={gen} | n={len(fits)} | "
                  f"P10={p10:.0f} | P50={p50:.0f} | P90={p90:.0f} | "
                  f"top_50%={top_ratio:.1%} | mismatch_pairs={mismatch_count}/{total_pairs}")
        
        # é‡ç½®
        self.parent_fits = []
    
    def hgrex_step_record(self, source: str):
        """
        è®°å½• HGreX æ¯ä¸€æ­¥çš„å€™é€‰æ¥æº
        source: 'parent' / 'knn' / 'random' / 'fullscan'
        """
        self.hgrex_total_steps += 1
        if source == 'parent':
            self.hgrex_parent_edge += 1
        elif source == 'knn':
            self.hgrex_knn_fallback += 1
        elif source == 'random':
            self.hgrex_random_fallback += 1
        elif source == 'fullscan':
            self.hgrex_fullscan_fallback += 1
    
    def hgrex_fallback_breakdown(self, gen: int):
        """
        [XOV] hgrex_fallback_breakdown
        HGreX åˆ†å±‚å€™é€‰è¯¦ç»†ç»Ÿè®¡
        """
        total = max(1, self.hgrex_total_steps)
        
        self._log(f"[XOV] hgrex_breakdown | gen={gen} | total_steps={total} | "
                  f"parent={self.hgrex_parent_edge} ({self.hgrex_parent_edge/total:.1%}) | "
                  f"knn={self.hgrex_knn_fallback} ({self.hgrex_knn_fallback/total:.1%}) | "
                  f"random={self.hgrex_random_fallback} ({self.hgrex_random_fallback/total:.1%}) | "
                  f"fullscan={self.hgrex_fullscan_fallback} ({self.hgrex_fullscan_fallback/total:.1%})")
        
        # é‡ç½®
        self.hgrex_parent_edge = 0
        self.hgrex_knn_fallback = 0
        self.hgrex_random_fallback = 0
        self.hgrex_fullscan_fallback = 0
        self.hgrex_total_steps = 0
    
    def pipe_record(self, stage: str, count: int = 1, op_type: str = None):
        """
        è®°å½•æµæ°´çº¿å„é˜¶æ®µ
        stage: 'generated' / 'feasible' / 'tamed' / 'submitted' / 'accepted'
        """
        if stage == 'generated' and op_type:
            if op_type not in self.pipe_generated:
                self.pipe_generated[op_type] = 0
            self.pipe_generated[op_type] += count
        elif stage == 'feasible':
            self.pipe_feasible += count
        elif stage == 'tamed':
            self.pipe_tamed += count
        elif stage == 'submitted':
            self.pipe_submitted += count
        elif stage == 'accepted':
            self.pipe_accepted += count
    
    def pipe_offspring_flow_report(self, gen: int):
        """
        [PIPE] offspring_flow_report
        ä»ç”Ÿæˆåˆ°å†™å›çš„å®Œæ•´æµæ°´çº¿ç»Ÿè®¡
        """
        total_gen = sum(self.pipe_generated.values())
        
        self._log(f"[PIPE] offspring_flow | gen={gen} | "
                  f"generated={total_gen} (HGreX={self.pipe_generated.get('hgrex', 0)}, "
                  f"OX={self.pipe_generated.get('ox', 0)}, Mut={self.pipe_generated.get('mutate', 0)}) | "
                  f"feasible={self.pipe_feasible} | tamed={self.pipe_tamed} | "
                  f"submitted={self.pipe_submitted} | accepted={self.pipe_accepted}")
        
        # é‡ç½®
        self.pipe_generated = {'hgrex': 0, 'ox': 0, 'mutate': 0}
        self.pipe_feasible = 0
        self.pipe_tamed = 0
        self.pipe_submitted = 0
        self.pipe_accepted = 0


