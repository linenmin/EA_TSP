"""
è¯Šæ–­è„šæœ¬ï¼šå¯¹æ¯” LKH3 æœ€ä½³è·¯å¾„ä¸ä½ çš„ç®—æ³•è¾“å‡º

ä½¿ç”¨æ–¹æ³•ï¼š
    1. å…ˆç”¨ get_optimal_reference.py ç”Ÿæˆ best_route_tour750.txt
    2. åœ¨ r0927480.py ä¸­ import æœ¬æ¨¡å—å¹¶è°ƒç”¨è¯Šæ–­å‡½æ•°

è¯Šæ–­ç»´åº¦ï¼š
    - è¾¹ç›¸ä¼¼åº¦ (Edge Similarity): ä½ çš„è§£æœ‰å¤šå°‘è¾¹ä¸ LKH3 ç›¸åŒ
    - å€™é€‰è¾¹è¦†ç›–ç‡ (Candidate Coverage): LKH3 ä½¿ç”¨çš„è¾¹æœ‰å¤šå°‘åœ¨ä½ çš„å€™é€‰é›†ä¸­
    - Bond Distance: è§£ä¸è§£ä¹‹é—´çš„ç»“æ„è·ç¦»
"""

import numpy as np

def load_lkh_route(filename):
    """
    åŠ è½½ LKH3 æœ€ä½³è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªèŠ‚ç‚¹ç´¢å¼•ï¼‰
    
    æ³¨æ„ï¼šLKH è¾“å‡ºçš„æ ¼å¼å¯èƒ½æ˜¯ "èµ·ç‚¹ -> ... -> èµ·ç‚¹"ï¼Œ
    ä¼šè‡ªåŠ¨å»é™¤é‡å¤çš„èµ·ç‚¹èŠ‚ç‚¹ã€‚
    """
    route = []
    with open(filename, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                route.append(int(line))
    
    # å¦‚æœæœ€åä¸€ä¸ªèŠ‚ç‚¹ç­‰äºç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆå›åˆ°èµ·ç‚¹ï¼‰ï¼Œåˆ™å»é™¤
    if len(route) > 1 and route[-1] == route[0]:
        route = route[:-1]
    
    return np.array(route, dtype=np.int32)


def get_edges_set(tour):
    """å°† tour è½¬æ¢ä¸ºè¾¹é›†åˆï¼ˆæ— å‘è¾¹ç”¨ frozensetï¼Œæœ‰å‘è¾¹ç”¨ tupleï¼‰"""
    n = len(tour)
    edges_directed = set()
    edges_undirected = set()
    for i in range(n):
        u, v = tour[i], tour[(i + 1) % n]
        edges_directed.add((u, v))
        edges_undirected.add(frozenset([u, v]))
    return edges_directed, edges_undirected


def edge_similarity(tour1, tour2, directed=False):
    """
    è®¡ç®—ä¸¤ä¸ª tour çš„è¾¹ç›¸ä¼¼åº¦
    
    Args:
        tour1: ç¬¬ä¸€ä¸ª tour
        tour2: ç¬¬äºŒä¸ª tour (é€šå¸¸æ˜¯ LKH3 æœ€ä½³è·¯å¾„)
        directed: æ˜¯å¦è€ƒè™‘è¾¹çš„æ–¹å‘ï¼ˆéå¯¹ç§° TSP è®¾ä¸º Trueï¼‰
    
    Returns:
        shared_count: å…±äº«è¾¹æ•°é‡
        ratio: é‡åˆç‡ (shared_count / n)
    """
    d1, u1 = get_edges_set(tour1)
    d2, u2 = get_edges_set(tour2)
    
    if directed:
        shared = d1 & d2
    else:
        shared = u1 & u2
    
    n = len(tour1)
    return len(shared), len(shared) / n


def bond_distance(tour1, tour2):
    """
    è®¡ç®— Bond Distanceï¼ˆç»“æ„è·ç¦»ï¼‰
    
    Bond Distance = n - å…±äº«è¾¹æ•°é‡
    æ•°å€¼è¶Šå°ï¼Œè¡¨ç¤ºä¸¤ä¸ª tour ç»“æ„è¶Šç›¸ä¼¼
    """
    n = len(tour1)
    _, u1 = get_edges_set(tour1)
    _, u2 = get_edges_set(tour2)
    shared = len(u1 & u2)
    return n - shared


def find_missing_edges(my_tour, lkh_tour, D=None):
    """
    æ‰¾å‡º LKH3 ç”¨äº†ä½†ä½ æ²¡ç”¨çš„è¾¹
    
    Returns:
        missing_edges: åˆ—è¡¨ [(u, v, distance), ...]
    """
    _, my_edges = get_edges_set(my_tour)
    _, lkh_edges = get_edges_set(lkh_tour)
    
    missing = lkh_edges - my_edges
    
    result = []
    for edge in missing:
        edge_list = list(edge)
        # å¤„ç†å•å…ƒç´  frozensetï¼ˆç†è®ºä¸Šä¸åº”è¯¥å­˜åœ¨ï¼Œä½†ä»¥é˜²ä¸‡ä¸€ï¼‰
        if len(edge_list) < 2:
            continue
        u, v = edge_list[0], edge_list[1]
        dist = D[u, v] if D is not None else None
        result.append((u, v, dist))
    
    # æŒ‰è·ç¦»æ’åºï¼ˆå¦‚æœæœ‰è·ç¦»ä¿¡æ¯ï¼‰
    if D is not None:
        result.sort(key=lambda x: x[2])
    
    return result


def candidate_coverage(lkh_tour, knn_idx):
    """
    æ£€æŸ¥ LKH3 ä½¿ç”¨çš„è¾¹æœ‰å¤šå°‘è¢« knn_idx å€™é€‰è¦†ç›–
    
    Args:
        lkh_tour: LKH3 æœ€ä½³è·¯å¾„
        knn_idx: ä½ çš„ KNN å€™é€‰è¾¹ (n, K)
    
    Returns:
        covered_count: è¢«è¦†ç›–çš„è¾¹æ•°é‡
        ratio: è¦†ç›–ç‡
        uncovered_edges: æœªè¢«è¦†ç›–çš„è¾¹åˆ—è¡¨ [(u, v), ...]
    """
    n = len(lkh_tour)
    K = knn_idx.shape[1]
    
    # å°† knn_idx è½¬ä¸ºå¿«é€ŸæŸ¥æ‰¾ç»“æ„
    candidate_sets = [set(knn_idx[i]) - {-1} for i in range(n)]
    
    covered = 0
    uncovered_edges = []
    
    for i in range(n):
        u, v = lkh_tour[i], lkh_tour[(i + 1) % n]
        
        # æ£€æŸ¥ u->v æˆ– v->u æ˜¯å¦åœ¨å€™é€‰ä¸­
        if v in candidate_sets[u] or u in candidate_sets[v]:
            covered += 1
        else:
            uncovered_edges.append((u, v))
    
    return covered, covered / n, uncovered_edges


def diagnose_full(my_tour, lkh_tour, D, knn_idx=None, label=""):
    """
    å®Œæ•´è¯Šæ–­è¾“å‡º
    
    Args:
        my_tour: ä½ çš„ç®—æ³•å½“å‰æœ€ä¼˜è§£
        lkh_tour: LKH3 æœ€ä½³è·¯å¾„
        D: è·ç¦»çŸ©é˜µ
        knn_idx: å¯é€‰ï¼Œä½ çš„ KNN å€™é€‰è¾¹
        label: è¯Šæ–­æ ‡ç­¾ï¼ˆå¦‚ "Gen 100"ï¼‰
    """
    n = len(my_tour)
    
    # 1. è®¡ç®—è·¯å¾„é•¿åº¦
    my_length = sum(D[my_tour[i], my_tour[(i + 1) % n]] for i in range(n))
    lkh_length = sum(D[lkh_tour[i], lkh_tour[(i + 1) % n]] for i in range(n))
    gap = (my_length - lkh_length) / lkh_length * 100
    
    # 2. è¾¹ç›¸ä¼¼åº¦
    shared, ratio = edge_similarity(my_tour, lkh_tour, directed=False)
    bond_dist = bond_distance(my_tour, lkh_tour)
    
    # 3. æ‰¾ç¼ºå¤±è¾¹ï¼ˆLKH ç”¨äº†ä½ æ²¡ç”¨ï¼‰
    missing = find_missing_edges(my_tour, lkh_tour, D)
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ è¯Šæ–­æŠ¥å‘Š {label}")
    print(f"{'='*60}")
    print(f"  ğŸ“ ä½ çš„è·¯å¾„é•¿åº¦: {my_length:.2f}")
    print(f"  ğŸ† LKH3 æœ€ä½³é•¿åº¦: {lkh_length:.2f}")
    print(f"  ğŸ“Š å·®è· (Gap): {gap:.4f}%")
    print(f"\n  ğŸ”— è¾¹ç›¸ä¼¼åº¦: {shared}/{n} ({ratio*100:.2f}%)")
    print(f"  ğŸ“ Bond Distance: {bond_dist}")
    
    # 4. å€™é€‰è¦†ç›–ç‡
    if knn_idx is not None:
        cov_count, cov_ratio, uncovered = candidate_coverage(lkh_tour, knn_idx)
        print(f"\n  ğŸ“‹ å€™é€‰è¦†ç›–ç‡: {cov_count}/{n} ({cov_ratio*100:.2f}%)")
        if uncovered:
            print(f"  âš ï¸  LKH3 ä½¿ç”¨ä½†ä½ çš„å€™é€‰æœªè¦†ç›–çš„è¾¹ (å‰5ä¸ª):")
            for u, v in uncovered[:5]:
                print(f"      - ({u}, {v}), è·ç¦»: {D[u, v]:.2f}")
    
    # # 5. æ˜¾ç¤º LKH3 ç”¨äº†ä½ æ²¡ç”¨çš„è¾¹ä¸­è·ç¦»æœ€çŸ­çš„å‡ ä¸ª
    # if missing:
    #     print(f"\n  ğŸ” LKH3 ç”¨äº†ä½†ä½ æ²¡ç”¨çš„è¾¹ (æŒ‰è·ç¦»æ’åºï¼Œå‰10ä¸ª):")
    #     for u, v, dist in missing[:10]:
    #         print(f"      - ({u}, {v}), è·ç¦»: {dist:.2f}")
    
    print(f"{'='*60}\n")
    
    return {
        "my_length": my_length,
        "lkh_length": lkh_length,
        "gap_pct": gap,
        "edge_similarity": ratio,
        "bond_distance": bond_dist,
        "missing_edges": missing[:20]
    }


# =============================================================================
# å¯ä»¥åœ¨ r0927480.py ä¸­è°ƒç”¨çš„è¾…åŠ©å‡½æ•°
# =============================================================================

_LKH_ROUTE = None  # ç¼“å­˜ LKH æœ€ä½³è·¯å¾„

def init_lkh_reference(filename):
    """åˆå§‹åŒ– LKH å‚è€ƒè·¯å¾„ï¼ˆåªéœ€è°ƒç”¨ä¸€æ¬¡ï¼‰"""
    global _LKH_ROUTE
    try:
        _LKH_ROUTE = load_lkh_route(filename)
        print(f"âœ… åŠ è½½ LKH å‚è€ƒè·¯å¾„: {filename} (n={len(_LKH_ROUTE)})")
    except FileNotFoundError:
        print(f"âš ï¸ æœªæ‰¾åˆ° LKH å‚è€ƒè·¯å¾„: {filename}")
        _LKH_ROUTE = None


def quick_diagnose(my_tour, D, knn_idx=None, label=""):
    """å¿«é€Ÿè¯Šæ–­ï¼ˆåœ¨ç®—æ³•è¿è¡Œä¸­å‘¨æœŸæ€§è°ƒç”¨ï¼‰"""
    global _LKH_ROUTE
    if _LKH_ROUTE is None:
        return None
    
    return diagnose_full(my_tour, _LKH_ROUTE, D, knn_idx, label)


# =============================================================================
# é«˜çº§è¯Šæ–­å‡½æ•°ï¼šç§ç¾¤å¤šæ ·æ€§ã€Scout æ•ˆèƒ½ã€GLS çŠ¶æ€ç­‰
# =============================================================================

def calc_pop_diversity(population, sample_pairs=10):
    """
    è®¡ç®—ç§ç¾¤å¤šæ ·æ€§ï¼ˆå¹³å‡ Bond Distanceï¼‰
    
    Args:
        population: ç§ç¾¤ (lam, n)
        sample_pairs: é‡‡æ ·å¯¹æ•°
    
    Returns:
        avg_bond_dist: å¹³å‡ Bond Distance
        diversity_ratio: å¤šæ ·æ€§æ¯”ç‡ (avg_bond_dist / n)
    """
    lam, n = population.shape
    if lam < 2:
        return 0.0, 0.0
    
    total_dist = 0.0
    pairs = min(sample_pairs, lam * (lam - 1) // 2)
    
    for _ in range(pairs):
        i = np.random.randint(0, lam)
        j = np.random.randint(0, lam - 1)
        if j >= i:
            j += 1
        total_dist += bond_distance(population[i], population[j])
    
    avg_dist = total_dist / pairs if pairs > 0 else 0.0
    return avg_dist, avg_dist / n


def count_distinct_tours(population):
    """
    ç»Ÿè®¡ç§ç¾¤ä¸­ä¸åŒè§£çš„æ•°é‡ï¼ˆç”¨äºæ£€æµ‹æ—©ç†Ÿï¼‰
    
    Returns:
        distinct_count: ä¸åŒè§£çš„æ•°é‡
    """
    seen = set()
    for tour in population:
        # ç”¨ tour çš„å“ˆå¸Œä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼ˆç®€åŒ–ç‰ˆï¼šç”¨å‰10ä¸ªå’Œå10ä¸ªå…ƒç´ ï¼‰
        key = tuple(tour[:10]) + tuple(tour[-10:])
        seen.add(key)
    return len(seen)


def analyze_error_edges(my_tour, lkh_tour, D):
    """
    åˆ†æé”™è¯¯è¾¹çš„ç‰¹å¾
    
    Returns:
        my_avg_edge_len: æˆ‘çš„è§£çš„å¹³å‡è¾¹é•¿åº¦
        lkh_avg_edge_len: LKH è§£çš„å¹³å‡è¾¹é•¿åº¦
        missing_avg_len: ç¼ºå¤±è¾¹çš„å¹³å‡é•¿åº¦
        extra_avg_len: å¤šä½™è¾¹çš„å¹³å‡é•¿åº¦
    """
    n = len(my_tour)
    
    # è®¡ç®—è¾¹é›†åˆ
    _, my_edges = get_edges_set(my_tour)
    _, lkh_edges = get_edges_set(lkh_tour)
    
    # å…±äº«è¾¹ã€ç¼ºå¤±è¾¹ã€å¤šä½™è¾¹
    shared = my_edges & lkh_edges
    missing = lkh_edges - my_edges  # LKH æœ‰ä½†æˆ‘æ²¡æœ‰
    extra = my_edges - lkh_edges    # æˆ‘æœ‰ä½† LKH æ²¡æœ‰
    
    # è®¡ç®—å¹³å‡è¾¹é•¿åº¦
    def avg_edge_length(edge_set, D):
        if not edge_set:
            return 0.0
        total = 0.0
        count = 0
        for edge in edge_set:
            edge_list = list(edge)
            if len(edge_list) >= 2:
                u, v = edge_list[0], edge_list[1]
                if np.isfinite(D[u, v]):
                    total += D[u, v]
                    count += 1
        return total / count if count > 0 else 0.0
    
    my_avg = avg_edge_length(my_edges, D)
    lkh_avg = avg_edge_length(lkh_edges, D)
    missing_avg = avg_edge_length(missing, D)
    extra_avg = avg_edge_length(extra, D)
    
    return {
        "my_avg_edge_len": my_avg,
        "lkh_avg_edge_len": lkh_avg,
        "missing_avg_len": missing_avg,
        "extra_avg_len": extra_avg,
        "shared_count": len(shared),
        "missing_count": len(missing),
        "extra_count": len(extra)
    }


def check_gls_penalty_quality(tour, D, gls_penalties, lkh_tour):
    """
    æ£€æŸ¥ GLS æƒ©ç½šçš„è´¨é‡ï¼šæ˜¯å¦æ­£ç¡®æƒ©ç½šäº†é”™è¯¯è¾¹
    
    Returns:
        correct_penalty_ratio: æ­£ç¡®è¾¹ä¸­è¢«æƒ©ç½šçš„æ¯”ä¾‹ï¼ˆåº”è¯¥ä½ï¼‰
        wrong_penalty_ratio: é”™è¯¯è¾¹ä¸­è¢«æƒ©ç½šçš„æ¯”ä¾‹ï¼ˆåº”è¯¥é«˜ï¼‰
    """
    n = len(tour)
    _, my_edges = get_edges_set(tour)
    _, lkh_edges = get_edges_set(lkh_tour)
    
    # æ­£ç¡®è¾¹ = å…±äº«è¾¹ï¼Œé”™è¯¯è¾¹ = æˆ‘æœ‰ä½† LKH æ²¡æœ‰
    shared = my_edges & lkh_edges
    extra = my_edges - lkh_edges
    
    def get_penalty_ratio(edge_set):
        if not edge_set:
            return 0.0
        penalized = 0
        for edge in edge_set:
            edge_list = list(edge)
            if len(edge_list) >= 2:
                u, v = edge_list[0], edge_list[1]
                if gls_penalties[u, v] > 0 or gls_penalties[v, u] > 0:
                    penalized += 1
        return penalized / len(edge_set)
    
    return {
        "correct_edge_penalty_ratio": get_penalty_ratio(shared),
        "wrong_edge_penalty_ratio": get_penalty_ratio(extra),
        "max_penalty": int(gls_penalties.max()),
        "nonzero_count": int(np.count_nonzero(gls_penalties))
    }


def advanced_diagnose(my_tour, D, population=None, gls_penalties=None, 
                      scout_accepted=0, scout_total=0, label=""):
    """
    é«˜çº§è¯Šæ–­è¾“å‡ºï¼ˆåœ¨ quick_diagnose åŸºç¡€ä¸Šå¢åŠ æ›´å¤šæŒ‡æ ‡ï¼‰
    """
    global _LKH_ROUTE
    if _LKH_ROUTE is None:
        return None
    
    n = len(my_tour)
    lkh_tour = _LKH_ROUTE
    
    # åŸºç¡€æŒ‡æ ‡
    my_length = sum(D[my_tour[i], my_tour[(i + 1) % n]] for i in range(n))
    lkh_length = sum(D[lkh_tour[i], lkh_tour[(i + 1) % n]] for i in range(n))
    gap = (my_length - lkh_length) / lkh_length * 100
    shared, ratio = edge_similarity(my_tour, lkh_tour, directed=False)
    
    # é”™è¯¯è¾¹åˆ†æ
    error_analysis = analyze_error_edges(my_tour, lkh_tour, D)
    
    print(f"\n{'='*70}")
    print(f"ğŸ”¬ é«˜çº§è¯Šæ–­ {label}")
    print(f"{'='*70}")
    print(f"  ğŸ“Š Gap: {gap:.4f}% | è¾¹ç›¸ä¼¼åº¦: {shared}/{n} ({ratio*100:.1f}%)")
    
    # é”™è¯¯è¾¹ç‰¹å¾
    print(f"  ğŸ“ è¾¹é•¿åº¦å¯¹æ¯”:")
    print(f"      æˆ‘çš„å¹³å‡è¾¹é•¿: {error_analysis['my_avg_edge_len']:.2f}")
    print(f"      LKH å¹³å‡è¾¹é•¿: {error_analysis['lkh_avg_edge_len']:.2f}")
    print(f"      ç¼ºå¤±è¾¹å¹³å‡é•¿: {error_analysis['missing_avg_len']:.2f} (åº”è¯¥ç”¨è¿™äº›)")
    print(f"      å¤šä½™è¾¹å¹³å‡é•¿: {error_analysis['extra_avg_len']:.2f} (ä¸åº”è¯¥ç”¨è¿™äº›)")
    
    greedy_indicator = error_analysis['extra_avg_len'] < error_analysis['missing_avg_len']
    if greedy_indicator:
        print(f"      âš ï¸ è¯Šæ–­: ç®—æ³•è¿‡äºè´ªå©ªï¼Œé€‰æ‹©äº†æ›´çŸ­ä½†éæœ€ä¼˜çš„è¾¹ï¼")
    else:
        print(f"      â„¹ï¸ è¯Šæ–­: ç®—æ³•å¯èƒ½ä¼˜åŒ–åŠ›åº¦ä¸å¤Ÿ")
    
    # ç§ç¾¤å¤šæ ·æ€§
    if population is not None:
        avg_dist, div_ratio = calc_pop_diversity(population, 15)
        distinct = count_distinct_tours(population)
        print(f"  ğŸ‘¥ ç§ç¾¤å¤šæ ·æ€§:")
        print(f"      å¹³å‡ Bond Distance: {avg_dist:.1f} ({div_ratio*100:.1f}% of n)")
        print(f"      ä¸åŒè§£æ•°é‡: {distinct}/{len(population)}")
        if div_ratio < 0.05:
            print(f"      âš ï¸ è­¦å‘Š: ç§ç¾¤ä¸¥é‡æ—©ç†Ÿï¼")
    
    # GLS çŠ¶æ€ (Vanilla GLS: high penalty rate is NORMAL!)
    if gls_penalties is not None:
        gls_info = check_gls_penalty_quality(my_tour, D, gls_penalties, lkh_tour)
        print(f"  ğŸ¯ GLS æƒ©ç½šçŠ¶æ€ (Vanillaæ¨¡å¼):")
        print(f"      Max Penalty: {gls_info['max_penalty']} | éé›¶æ•°é‡: {gls_info['nonzero_count']}")
        print(f"      æ­£ç¡®è¾¹è¢«æƒ©ç½š: {gls_info['correct_edge_penalty_ratio']*100:.1f}% (Vanilla: é«˜æ˜¯æ­£å¸¸çš„!)")
        print(f"      é”™è¯¯è¾¹è¢«æƒ©ç½š: {gls_info['wrong_edge_penalty_ratio']*100:.1f}%")
    
    # Scout æ•ˆèƒ½
    if scout_total > 0:
        acc_rate = scout_accepted / scout_total * 100
        print(f"  ğŸ¦… Scout æ•ˆèƒ½: {scout_accepted}/{scout_total} ({acc_rate:.1f}%)")
    
    print(f"{'='*70}\n")
    
    return {
        "gap": gap,
        "similarity": ratio,
        "error_analysis": error_analysis
    }


# =============================================================================
# ç¤ºä¾‹ç”¨æ³•
# =============================================================================

if __name__ == "__main__":
    import sys
    
    # ç¤ºä¾‹ï¼šåŠ è½½å¹¶å¯¹æ¯”
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python diagnose_gap.py <tour_csv> <lkh_route.txt>")
        print("ç¤ºä¾‹: python diagnose_gap.py tour750.csv best_route_tour750.txt")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    lkh_file = sys.argv[2]
    
    # åŠ è½½è·ç¦»çŸ©é˜µ
    D = np.loadtxt(csv_file, delimiter=',')
    n = D.shape[0]
    
    # åŠ è½½ LKH æœ€ä½³è·¯å¾„
    lkh_tour = load_lkh_route(lkh_file)
    
    # ç”Ÿæˆä¸€ä¸ªç®€å•çš„è´ªå¿ƒè§£ä½œä¸ºå¯¹æ¯”
    from get_optimal_reference import method_elkai
    _, my_tour = method_elkai(D, precision=1, runs=1)  # åªè·‘ 1 æ¬¡ä½œä¸ºå¿«é€Ÿæµ‹è¯•
    
    if my_tour is not None:
        my_tour = np.array(my_tour, dtype=np.int32)
        
        # æ„å»º KNN å€™é€‰
        finite_mask = np.isfinite(D)
        K = 32
        knn_idx = np.full((n, K), -1, np.int32)
        for i in range(n):
            row = D[i]
            valid = np.where(finite_mask[i])[0]
            if len(valid) > 0:
                order = np.argsort(row[valid])
                m = min(K, len(valid))
                knn_idx[i, :m] = valid[order[:m]]
        
        diagnose_full(my_tour, lkh_tour, D, knn_idx, label="å¿«é€Ÿæµ‹è¯•")

# =============================================================================
# God Mode Debugging Tools
# =============================================================================

def create_golden_individual(D, lkh_tour, ruin_percent=0.3):
    """
    Generate 'Golden Individual': preserve (1-ruin_percent) of LKH optimal,
    destroy and repair the rest with greedy strategy.
    Used to test: will the algorithm 'optimize' this near-perfect solution badly?
    """
    n = len(lkh_tour)
    n_remove = int(n * ruin_percent)
    
    # 1. Copy LKH genes
    tour = lkh_tour.copy()
    
    # 2. Randomly destroy a contiguous region (Sequence Ruin)
    start = np.random.randint(0, n)
    mask = np.zeros(n, dtype=np.bool_)
    for i in range(n_remove):
        mask[tour[(start + i) % n]] = True
        
    # 3. Extract kept and removed cities
    kept = []
    removed = []
    for city in tour:
        if mask[city]: removed.append(city)
        else: kept.append(city)
    
    # Shuffle removed and reinsert with greedy
    current_tour = list(kept)
    np.random.shuffle(removed)
    
    # Cheapest Insertion
    for city in removed:
        best_delta = 1e20
        best_pos = -1
        m = len(current_tour)
        for i in range(m):
            u, v = current_tour[i], current_tour[(i + 1) % m]
            delta = D[u, city] + D[city, v] - D[u, v]
            if delta < best_delta:
                best_delta = delta
                best_pos = i
        current_tour.insert(best_pos + 1, city)
        
    return np.array(current_tour, dtype=np.int32)

def analyze_missing_topology(my_tour, lkh_tour):
    """
    Analyze missing edges (dead knots) topology
    """
    n = len(my_tour)
    _, my_edges = get_edges_set(my_tour)
    _, lkh_edges = get_edges_set(lkh_tour)
    
    # Find edges LKH has but I don't
    missing = list(lkh_edges - my_edges)
    missing_count = len(missing)
    
    print(f"\nğŸ” æ‹“æ‰‘æ­»ç»“åˆ†æ:")
    print(f"   ç¼ºå¤±è¾¹æ•°é‡: {missing_count} (è¿™äº›è¾¹æ„æˆäº†ä½ æ— æ³•è·¨è¶Šçš„å¢™)")
    
    if missing_count == 0:
        print("   âœ… æ²¡æœ‰ç¼ºå¤±è¾¹ï¼Œå·²è¾¾åˆ°æœ€ä¼˜è§£ï¼")
        return

    # Build adjacency for connectivity analysis
    adj = {}
    nodes = set()
    for edge in missing:
        u, v = list(edge)
        if u not in adj: adj[u] = []
        if v not in adj: adj[v] = []
        adj[u].append(v)
        adj[v].append(u)
        nodes.add(u)
        nodes.add(v)
        
    # Find connected components
    visited = set()
    chains = 0
    cycles = 0
    complex_knots = 0
    
    for node in nodes:
        if node not in visited:
            # BFS for connected component
            component_nodes = []
            stack = [node]
            visited.add(node)
            while stack:
                curr = stack.pop()
                component_nodes.append(curr)
                for neighbor in adj[curr]:
                    if neighbor not in visited:
                        visited.add(neighbor)
                        stack.append(neighbor)
            
            # Analyze component
            comp_edges = 0
            for u in component_nodes:
                comp_edges += len(adj[u])
            comp_edges //= 2
            
            size = len(component_nodes)
            
            if size == comp_edges:
                cycles += 1
                knot_type = "ğŸ”’ é—­ç¯ (Cycle)"
            elif size == comp_edges + 1:
                chains += 1
                knot_type = "ğŸ”— é“¾æ¡ (Chain)"
            else:
                complex_knots += 1
                knot_type = "ğŸ•¸ï¸ å¤æ‚çº ç¼  (Complex)"
            
            print(f"   - ç»„ä»¶: {size} èŠ‚ç‚¹, {comp_edges} è¾¹ -> {knot_type}")

    print(f"   ğŸ“Š æ€»ç»“: {chains} æ¡é“¾, {cycles} ä¸ªç¯, {complex_knots} ä¸ªå¤æ‚çº ç¼ ")
    
    if cycles > 0 or complex_knots > 0:
        print("   ğŸš¨ ç»“è®º: å­˜åœ¨é—­ç¯æˆ–å¤æ‚çº ç¼ ã€‚2-opt/3-opt æ— æ³•è§£å¼€ã€‚")
        print("      éœ€è¦ Double Bridge (4-opt) æˆ– Ejection Chainsã€‚")
    else:
        print("   âœ… ç»“è®º: é”™è¯¯è¾¹æ¯”è¾ƒåˆ†æ•£ï¼ŒGLS åº”è¯¥èƒ½è§£å†³ã€‚")
